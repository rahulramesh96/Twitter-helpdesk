{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ServerSelectionTimeoutError",
     "evalue": "localhost:27017: [Errno 111] Connection refused",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mServerSelectionTimeoutError\u001b[0m               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f41427853858>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mscreen_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'ola_supports'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMongoClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_database\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'not-truncated'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mconvs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconversations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'screen_name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscreen_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'topics'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'$ne'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'There are total'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'conversations.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/expedite/lib/python3.6/site-packages/pymongo/cursor.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1112\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0m_db\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__collection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatabase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_refresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__manipulate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m                 return _db._fix_outgoing(self.__data.popleft(),\n",
      "\u001b[0;32m~/.miniconda3/envs/expedite/lib/python3.6/site-packages/pymongo/cursor.py\u001b[0m in \u001b[0;36m_refresh\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1034\u001b[0m                                        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__batch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__read_concern\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1036\u001b[0;31m                                        self.__collation))\n\u001b[0m\u001b[1;32m   1037\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__id\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__killed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/expedite/lib/python3.6/site-packages/pymongo/cursor.py\u001b[0m in \u001b[0;36m__send_message\u001b[0;34m(self, operation)\u001b[0m\n\u001b[1;32m    871\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m                 response = client._send_message_with_response(operation,\n\u001b[0;32m--> 873\u001b[0;31m                                                               **kwargs)\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__address\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__exhaust\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/expedite/lib/python3.6/site-packages/pymongo/mongo_client.py\u001b[0m in \u001b[0;36m_send_message_with_response\u001b[0;34m(self, operation, read_preference, exhaust, address)\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mselector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_preference\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mwritable_server_selector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m             \u001b[0mserver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopology\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_server\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m         \u001b[0;31m# A _Query's slaveOk bit is already set for queries with non-primary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/expedite/lib/python3.6/site-packages/pymongo/topology.py\u001b[0m in \u001b[0;36mselect_server\u001b[0;34m(self, selector, server_selection_timeout, address)\u001b[0m\n\u001b[1;32m    212\u001b[0m         return random.choice(self.select_servers(selector,\n\u001b[1;32m    213\u001b[0m                                                  \u001b[0mserver_selection_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m                                                  address))\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     def select_server_by_address(self, address,\n",
      "\u001b[0;32m~/.miniconda3/envs/expedite/lib/python3.6/site-packages/pymongo/topology.py\u001b[0m in \u001b[0;36mselect_servers\u001b[0;34m(self, selector, server_selection_timeout, address)\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mserver_timeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnow\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mend_time\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                     raise ServerSelectionTimeoutError(\n\u001b[0;32m--> 189\u001b[0;31m                         self._error_message(selector))\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_opened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mServerSelectionTimeoutError\u001b[0m: localhost:27017: [Errno 111] Connection refused"
     ]
    }
   ],
   "source": [
    "screen_name = 'ola_supports'\n",
    "db = MongoClient().get_database('not-truncated')\n",
    "convs = list(db.conversations.find({'screen_name': screen_name, 'topics': {'$ne': []}}))\n",
    "print('There are total', len(convs), 'conversations.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten it\n",
    "\n",
    "dataset = []\n",
    "topics_to_ignore = ['undefined', 'poor_experience', 'random_query']\n",
    "cant_coexist = [\n",
    "    ('overcharged', 'payments'),\n",
    "    ('cancellation_charged', 'overcharged'),\n",
    "    ('driver_denied', 'cancellation_charged'),\n",
    "]\n",
    "# cant_coexist = []\n",
    "\n",
    "multi_topic_convs = []\n",
    "\n",
    "for c in convs:\n",
    "    topics_here = [t for t in c['topics'] if t not in topics_to_ignore]\n",
    "    \n",
    "    # manually remove second topic from pairs if they co-exist\n",
    "    for to_keep, to_discard in cant_coexist:\n",
    "        if to_keep in topics_here and to_discard in topics_here:\n",
    "            topics_here.remove(to_discard)\n",
    "    \n",
    "    \n",
    "    for m in filter(lambda msg: msg['important'], c['messages']):\n",
    "        multi_topic_convs.append({'message': m['processed_text'], 'topics': topics_here})\n",
    "        for t in topics_here:\n",
    "            dataset.append({'message': m['processed_text'].replace('\\n', ''), 'topic': t})\n",
    "        \n",
    "multi_topic_df = pd.DataFrame(multi_topic_convs)\n",
    "df = pd.DataFrame(dataset)\n",
    "print(df.size, 'records')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get topic counts\n",
    "\n",
    "topic_counts = df['topic'].value_counts()\n",
    "print(topic_counts)\n",
    "print(topic_counts.sum())\n",
    "topic_counts.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove insignificant topics\n",
    "cutoff_freq = int(0.1 * len(convs))  # 10 % is manually selected, coz it's near 50\n",
    "print(cutoff_freq, 'is the cutoff frequency.')\n",
    "\n",
    "selected_topics = topic_counts[topic_counts > cutoff_freq]\n",
    "print('Selected topics are', selected_topics.index.values)\n",
    "\n",
    "l1 = df.size\n",
    "df = df.loc[df['topic'].isin(selected_topics.index.values)]\n",
    "l2 = df.size\n",
    "print(l1, 'records reduced to', l2, 'records.')\n",
    "\n",
    "original_df = df.copy()\n",
    "df['topic'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put topic_id on topics to make it a numerical value\n",
    "df['topic_id'] = df['topic'].factorize()[0]\n",
    "\n",
    "topic_id_df = df[['topic', 'topic_id']].drop_duplicates().sort_values('topic_id')\n",
    "topic_to_id = dict(topic_id_df.values)\n",
    "id_to_topic = dict(topic_id_df[['topic_id', 'topic']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get features and labels using text vectorization\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='utf-8',\n",
    "                       ngram_range=(1, 2), stop_words='english')\n",
    "features = tfidf.fit_transform(df.message)\n",
    "labels = df['topic_id']\n",
    "features.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find most correlated topics\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "N = 3\n",
    "for topic, topic_id in sorted(topic_to_id.items()):\n",
    "    features_chi2 = chi2(features, labels == topic_id)\n",
    "    indices = np.argsort(features_chi2[0])\n",
    "    feature_names = np.array(tfidf.get_feature_names())[indices]\n",
    "    unigrams = [v for v in feature_names if len(v.split()) == 1]\n",
    "    bigrams = [v for v in feature_names if len(v.split()) == 2]\n",
    "    trigrams = [v for v in feature_names if len(v.split()) == 3]\n",
    "    print('For', topic)\n",
    "    print('\\t', 'Unigrams >', unigrams[-N:])\n",
    "    print('\\t', 'Bigrams >', bigrams[-N:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make required imports for training on above dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# for metrics\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, confusion_matrix\n",
    "\n",
    "# for undersampling or oversampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import EditedNearestNeighbours as ENN\n",
    "\n",
    "# for some vis\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(df['message'], df['topic_id'], random_state=0)\n",
    "\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='utf-8',\n",
    "                       ngram_range=(1, 2), stop_words='english')\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "\n",
    "print(X_train_tfidf.shape, Y_train.shape, X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some custom accuracy methods\n",
    "\n",
    "def accuracy(clf):\n",
    "    Y_pred = clf.predict(tfidf.transform(multi_topic_df['message']))\n",
    "    total = sum(1 for a, p in zip(multi_topic_df['topics'], Y_pred) if id_to_topic[p] in a)\n",
    "    return total / len(multi_topic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try models one by one\n",
    "\n",
    "def run_a_model(model, imb=None):\n",
    "    print('Running for', model.__class__.__name__, 'with imbalance fixing by', imb.__name__ if imb else None)\n",
    "    if not imb:\n",
    "        clf = model.fit(X_train_tfidf, Y_train)\n",
    "    else:\n",
    "        X_train_res, Y_train_res = imb(random_state=0).fit_sample(X_train_tfidf, Y_train)\n",
    "        clf = model.fit(X_train_res, Y_train_res)\n",
    "    Y_pred = clf.predict(tfidf.transform(X_test))\n",
    "\n",
    "    print('Actual accuracy :', accuracy(clf))\n",
    "    print('Model Accuracy :', accuracy_score(Y_test, Y_pred))\n",
    "    print('Recall :', recall_score(Y_test, Y_pred, average='micro'))\n",
    "    print('Precision :', precision_score(Y_test, Y_pred, average='micro'))\n",
    "\n",
    "    conf_mat = confusion_matrix(Y_test, Y_pred)\n",
    "    n_topics = len(selected_topics)\n",
    "    fig, ax = plt.subplots(figsize=(n_topics, n_topics))\n",
    "    sns.heatmap(conf_mat, annot=True, fmt='d', \n",
    "                xticklabels=selected_topics.index.values,\n",
    "                yticklabels=selected_topics.index.values)\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.show()\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multinomial naive bayes\n",
    "run_a_model(MultinomialNB())\n",
    "run_a_model(MultinomialNB(), SMOTE)\n",
    "run_a_model(MultinomialNB(), ENN)\n",
    "\n",
    "# logistic regression\n",
    "run_a_model(LogisticRegression(random_state=0))\n",
    "run_a_model(LogisticRegression(random_state=0), SMOTE)\n",
    "run_a_model(LogisticRegression(random_state=0), ENN)\n",
    "\n",
    "# linear svc\n",
    "run_a_model(LinearSVC())\n",
    "run_a_model(LinearSVC(), SMOTE)\n",
    "run_a_model(LinearSVC(), ENN)\n",
    "\n",
    "# random forest classifier\n",
    "run_a_model(RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0))\n",
    "run_a_model(RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0), SMOTE)\n",
    "run_a_model(RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0), ENN)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:expedite]",
   "language": "python",
   "name": "conda-env-expedite-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
